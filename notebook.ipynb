{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/homebrew/anaconda3/lib/python3.11/site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/anaconda3/lib/python3.11/site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (4.9.0)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "filename = \"Test_Sample/pass.png\"\n",
    "image = Image.open(filename).convert('L')\n",
    "\n",
    "from transformers import CLIPSegProcessor, CLIPSegForImageSegmentation\n",
    "\n",
    "processor = CLIPSegProcessor.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "model = CLIPSegForImageSegmentation.from_pretrained(\"CIDAS/clipseg-rd64-refined\")\n",
    "\n",
    "image_3ch = Image.merge('RGB', (image, image, image))\n",
    "\n",
    "prompts = [\"black color\", \"squares\"]\n",
    "\n",
    "inputs = processor(text=prompts, images=[image_3ch] * len(prompts), padding=\"max_length\", return_tensors=\"pt\")\n",
    "\n",
    "import torch\n",
    "\n",
    "# predict\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "preds = outputs.logits\n",
    "\n",
    "# Convert predictions to PIL images\n",
    "segmentation_masks = []\n",
    "for i in range(len(prompts)):\n",
    "    # Convert tensor to numpy array and scale to 0-255\n",
    "    mask = torch.sigmoid(preds[i]).numpy()\n",
    "    mask = (mask * 255).astype(np.uint8)\n",
    "    # Convert to PIL Image\n",
    "    mask_image = Image.fromarray(mask)\n",
    "    segmentation_masks.append(mask_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAFgCAAAAACgCvyQAAAFKUlEQVR4Ae3b7XLaMBAFUNL3f2daMvmgkKk9Vu9FoNNfwZVW2qOVbJP2dPKHAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAj8JPD208Xnu3b+mvJsCc0znz9GN5M533z+Qnz/4dv07+s3nz5jfDf/vHLTMPSxO9pHEt/JXlCvP91neZngv1vc99m+0ku7N9J71v+fahvz5xatxH/9PHzo6jy+oQTvw7YW8jLyZLyd1IsVPJnvfbFFrvSAp/PtTKgHHKmPoaAV4RpwJZsh70znFvCqvqcWcKY8BqM2Vn1p4MH12dV9beBCCZeAC5nsqqebRoV3jRLwTWILfQQcXmzAgMMC4fBrV3Dh3rs2cLh6L+E7wIVKKVgdGqIDXHjePJR9oVMHuJDIrEMADq8MYMBJgfzdt1PB+TySqzAUuwM8NMXn7gw4vH6AAYcFwuFVMOCwQDh8pYInfkqLT60CHC6SqcMDDi9PAzi+DQeM4l+kNoDjSQwAxxe/ATyQf75rWnh14PjuWh04XcClX3rmd/rhEdIlvHoFH16YvR0B75U62K4BHD/nDub+3i09uQZw+pgb8Y3/98gG8BjAk/duAKd34dRL0ACe+4gIz64BPHWFpScHOCwMGHBYIBxeBQMOC4TDq2DAYYFw+OUrOPye4Qv39Hv88hUcPiFU8EsAp8+5NNJIfEfEiN6OvoB3II00ATyit6Mv4B1II00Aj+jt6At4B9JIE8Ajejv6At6BNNIE8Ijejr6AdyCNNAE8orej7/LA6e9JlgfeUYRDTQAP8W13BrxtNNSiA5w+6IYIsp07wNkchqL7ndwQ33bn9OZavoK3l2CsBeAxv83eHeD0QbeZ5uMadIDTB93j/DZH7gBvTuN1GwAOry1gwFGB+N1h9QqOP9+sDhzdHpfggMPEgAGHBcLhSxUcv1kfZYpPrAR8NP/n77c6sMe0cA2/yhERL5TwOhwPXzoi4oVyXCDcswQczmLi8IDDiwMYcFggHF4FA44KxJ8fVXB0/XwfHOYF/CrA8aMuDnV0gNIZ7FX56ALptyFQquCNWbzwX68OHD+7VgeO7x3AYWLAgMMC4fCtCo7fTMJOh8O3gA9P8Nk7Ag6vIGDAYYFweBUMOCwQDq+CAScF8o/nKji5fn9iAwYcFgiHV8GAwwLh8GtXcP4hwk0uXMCAXwa4sBvTVofi187gVf/xVA340PK/QCfA4UUE/CrAbnLhlVw1fO2ImPEporGrasAqeD2BRgGv/Kpc8e0Bd9KZbxv2zuDZhEvz6QFPVlwl394RcTq1Utq1krXJNCu4ltQu4lKjctKTvG4Usy4O9VEyDzfuptwd7XpbPgi6nXB7vGvi95/LzvV86wPeCV9dOL8FuN9O50c+wEwF/GE9rvx2njGvq1LyIwECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBAgQIECAAAECBJ5A4Df4vTYzjBd+wwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=352x352>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "im = segmentation_masks[2]\n",
    "bw_img = im.convert('L')\n",
    "\n",
    "THRESHOLD = 70\n",
    "for x in range(bw_img.width):\n",
    "    for y in range(bw_img.height):\n",
    "        if bw_img.getpixel((x, y)) < THRESHOLD:\n",
    "            bw_img.putpixel((x, y), 0)\n",
    "        else:\n",
    "            bw_img.putpixel((x, y), 255)\n",
    "            \n",
    "bw_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Left most white pixel: x = 99\n",
      "Right most white pixel: x = 257\n",
      "Top most white pixel: y = 98\n",
      "Bottom most white pixel: y = 254\n",
      "Center point: x = 178, y = 176\n"
     ]
    }
   ],
   "source": [
    "\n",
    "im = segmentation_masks[2]\n",
    "bw_img = im.convert('L')\n",
    "\n",
    "THRESHOLD = 70\n",
    "for x in range(bw_img.width):\n",
    "    for y in range(bw_img.height):\n",
    "        if bw_img.getpixel((x, y)) < THRESHOLD:\n",
    "            bw_img.putpixel((x, y), 0)\n",
    "        else:\n",
    "            bw_img.putpixel((x, y), 255)\n",
    "            \n",
    "bw_img\n",
    "\n",
    "# Initialize the boundary values\n",
    "left_most = bw_img.width  # Start with maximum possible value\n",
    "right_most = 0           # Start with minimum possible value\n",
    "top_most = bw_img.height # Start with maximum possible value\n",
    "bottom_most = 0         # Start with minimum possible value\n",
    "\n",
    "# Scan through all pixels\n",
    "for x in range(bw_img.width):\n",
    "    for y in range(bw_img.height):\n",
    "        if bw_img.getpixel((x, y)) == 255:  # If we find a white pixel\n",
    "            # Update boundaries\n",
    "            left_most = min(left_most, x)\n",
    "            right_most = max(right_most, x)\n",
    "            top_most = min(top_most, y)\n",
    "            bottom_most = max(bottom_most, y)\n",
    "\n",
    "print(f\"Left most white pixel: x = {left_most}\")\n",
    "print(f\"Right most white pixel: x = {right_most}\")\n",
    "print(f\"Top most white pixel: y = {top_most}\")\n",
    "print(f\"Bottom most white pixel: y = {bottom_most}\")\n",
    "\n",
    "# Calculate center coordinates\n",
    "center_x = (left_most + right_most) // 2\n",
    "center_y = (top_most + bottom_most) // 2\n",
    "\n",
    "print(f\"Center point: x = {center_x}, y = {center_y}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
